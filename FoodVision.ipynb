{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNVVZCb2Lelx2Ua2/1UEfN6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Importing PyTroch and setting up device agnostic code\n",
        "**Domain Libraries:** Check it out for dataloaders for any application you are working on"
      ],
      "metadata": {
        "id": "XzQX4ZDAISVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "PA_C-0bPIp-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get Data\n",
        "Our dataset is a subset of the Food101 dataset.\n",
        "\n",
        "Food101 starts with 101 different classes of food and 1000 images per class.\n",
        "\n",
        "Our dataset starts with 3 classes of food and only 10% of the images.\n",
        "\n",
        "When starting ML projects, it is important to try things on a small scale and then increase the scale."
      ],
      "metadata": {
        "id": "olHuzaOwI_ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to a data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download pizza, steak, and sushi data\n",
        "with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "    print(\"Downloading pizza, steak, sushi data...\")\n",
        "    f.write(request.content)\n",
        "\n",
        "# Unzip pizza, steak, and sushi data\n",
        "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "    print(\"Unzipping pizza, steak, sushi data...\")\n",
        "    zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "id": "9KbI26t7KMb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path"
      ],
      "metadata": {
        "id": "9ZJU1mQ-LmHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Becoming one with the data (data preparation and exploration)"
      ],
      "metadata": {
        "id": "xeZsoYBYLpdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"Walks through dir_path returning its contents.\"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "yDvlKbWxMPXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(image_path)"
      ],
      "metadata": {
        "id": "m5XbdM5OMpX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup train and test paths\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "id": "8HSfrGAtMqZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing and image\n",
        "\n",
        "1. Get all of the image paths\n",
        "2. Pick a random image path using Python's `random.choice()`\n",
        "3. Get the class name using `pathlib.Path.parent.stem`\n",
        "4. Since we're working with images, let's open the image with Python's PIL\n",
        "5. We'll then show the image and print metadata."
      ],
      "metadata": {
        "id": "ltHDTngbM2Sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# Set seed\n",
        "random.seed(42)\n",
        "\n",
        "# 1. Get all the image paths\n",
        "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
        "# image_path_list\n",
        "\n",
        "# 2. Pick a random image path\n",
        "random_image_path = random.choice(image_path_list)\n",
        "print(random_image_path)\n",
        "\n",
        "# 3. Get the class name using parent.stem\n",
        "image_class = random_image_path.parent.stem\n",
        "print(image_class)\n",
        "\n",
        "# 4. Open image\n",
        "img = Image.open(random_image_path)\n",
        "\n",
        "# 5. Print metadata\n",
        "print(f\"Image size: {img.size}\")\n",
        "img"
      ],
      "metadata": {
        "id": "wji-0IBfNLZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to visualize an image with matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Turn the image into an array\n",
        "img_as_array = np.asarray(img)\n",
        "\n",
        "# Plot the image with matplotlib\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(img_as_array)\n",
        "plt.title(f\"Image class: {image_class} | Image shape: {img_as_array.shape} -> (height, width, color_channels)\")\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "zQONTnTjORpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Transforming data into tensors\n",
        "Before we can use our image data with PyTorch:\n",
        "1. Turn your target data into tensors\n",
        "2. Turn it into a `torch.utils.data.Dataset` and subsequently a `torch.utils.data.DataLoader`. We'll call these `Dataset` and `DataLoader`"
      ],
      "metadata": {
        "id": "SIynA4kiP3Gq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "LyiniNxrQDiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transforming data with `torchvision.transforms`"
      ],
      "metadata": {
        "id": "CC1sB5nBQ3Ep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a transform for image\n",
        "data_transform = transforms.Compose([\n",
        "\n",
        "  # Resize the images to 64x64\n",
        "  transforms.Resize(size=(64, 64)),\n",
        "\n",
        "  # Flip the images randomly on the horizontal\n",
        "  transforms.RandomHorizontalFlip(p=0.5),\n",
        "\n",
        "  # Turn the image into a torch.Tensor\n",
        "  transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "UskfZUwXQ7pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform(img)"
      ],
      "metadata": {
        "id": "GaCcGjOpRlvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform(img).shape"
      ],
      "metadata": {
        "id": "NS3xCfH3RsKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_transformed_images(image_paths: list, transform, n=3, seed=42):\n",
        "  \"\"\"Selects random images from a path and loads/transforms them and then plots them.\"\"\"\n",
        "  if seed:\n",
        "    random.seed(seed)\n",
        "\n",
        "  random_image_paths = random.sample(image_paths, k=n)\n",
        "  for image_path in random_image_paths:\n",
        "    with Image.open(image_path) as f:\n",
        "      fig, ax = plt.subplots(nrows=1, ncols=2)\n",
        "      ax[0].imshow(f)\n",
        "      ax[0].set_title(f\"Original\\nSize: {f.size}\")\n",
        "      ax[0].axis(False)\n",
        "\n",
        "      # Transform and plot image\n",
        "      transformed_image = transform(f).permute(1, 2, 0) # We will need to change shape for matplotlib (C, H, W) -> (H, W, C)\n",
        "      ax[1].imshow(transformed_image)\n",
        "      ax[1].set_title(f\"Transformed\\nShape: {transformed_image.shape}\")\n",
        "      ax[1].axis(False)\n",
        "\n",
        "      fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16)\n",
        "\n",
        "plot_transformed_images(image_path_list, data_transform)"
      ],
      "metadata": {
        "id": "9NwIs3FlRwWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Option 1: Loading image data using `ImageFolder`\n",
        "\n",
        "We can load image classification data using `torchvision.datasets.ImageFolder`"
      ],
      "metadata": {
        "id": "WY3KhU3sTbP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use ImageFolder to create datasets\n",
        "from torchvision import datasets\n",
        "\n",
        "train_data = datasets.ImageFolder(root=train_dir, transform=data_transform, target_transform=None)\n",
        "test_data = datasets.ImageFolder(root=test_dir, transform=data_transform, target_transform=None)\n",
        "\n",
        "train_data, test_data"
      ],
      "metadata": {
        "id": "QlEOhcpWUfAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names as list\n",
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "4i3UFsRjVBQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names as dict\n",
        "class_dict = train_data.class_to_idx\n",
        "class_dict"
      ],
      "metadata": {
        "id": "3d6H6Z9IVJsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "pBPbviFKVSN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.samples[0]"
      ],
      "metadata": {
        "id": "G8mmkLNVVU8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Index on the train_data Dataset to get a single image and label\n",
        "img, label = train_data[0][0], train_data[0][1]\n",
        "print(f\"Image tensor:\\n{img}\")\n",
        "print(f\"Image shape: {img.shape}\\nImage datatype: {img.dtype}\")\n",
        "print(f\"Image label: {label}\")\n",
        "print(f\"Label datatype: {type(label)}\")"
      ],
      "metadata": {
        "id": "j8x3H3LHVYli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rearrange order of dimensions\n",
        "img_permute = img.permute(1, 2, 0)\n",
        "\n",
        "# Print out different shapes\n",
        "print(f\"Original shape: {img.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Image permuted: {img.permute(1, 2, 0).shape} -> [height, width, color_channels]\")\n",
        "\n",
        "# Plot the image\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(img_permute)\n",
        "plt.axis(False)\n",
        "plt.title(class_names[label], fontsize=14)"
      ],
      "metadata": {
        "id": "5KtTMQs1Vq0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Turn loaded images into DataLoaders\n",
        "A `DataLoader` is going to help us turn our dataset into an iterable and we can customing the batch size."
      ],
      "metadata": {
        "id": "WCuMOu-YV3wZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.cpu_count()"
      ],
      "metadata": {
        "id": "cKsf8oI3kc5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn train and test datasets into DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 1\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True,\n",
        "                              num_workers=1,) # Can set to os.cpu_count to use as many workers as cpus\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             num_workers=1,\n",
        "                             shuffle=False)\n",
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "WSzxDrnJjwS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader), len(test_dataloader)"
      ],
      "metadata": {
        "id": "hJ9iHkaokvQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = next(iter(train_dataloader))\n",
        "img.shape, label.shape"
      ],
      "metadata": {
        "id": "qp4hrVbLk-Gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Loading Image Data with a Custom `Dataset`\n",
        "1. Want to be able to load images from file.\n",
        "2. Want to be able to get class names from the Dataset.\n",
        "3. Want to be able to get classes as Dictionary from Dataset.\n",
        "\n",
        "Pros:\n",
        "* Can create a dataset out of almost anything.\n",
        "* Not limited to PyTorch pre-built Dataset functions.\n",
        "\n",
        "Cons:\n",
        "* Even though you can create Dataset out of almost anything, it does not mean it will work.\n",
        "* Using a custom dataset often results in us writing more code, which could be prone to errors or performance issues."
      ],
      "metadata": {
        "id": "9j2BCZFAlDZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import torch\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from typing import Tuple, Dict, List"
      ],
      "metadata": {
        "id": "uwooofa3mUhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instance of torchvision.datasets.ImageFolder()\n",
        "train_data.classes, train_data.class_to_idx"
      ],
      "metadata": {
        "id": "JiRKDQGynJow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a helper function to get class names\n",
        "We want a function to:\n",
        "1. Get the class names using `os.scandir()` to traverse a target directory (ideally, the directory is in standard image classification format)\n",
        "2. Raise an error if class names are not found.\n",
        "3. Turn class names into a dict and a list to return them."
      ],
      "metadata": {
        "id": "DSp5ba4dnSJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup path for target directory\n",
        "target_directory = train_dir\n",
        "print(f\"Target directory: {target_directory}\")\n",
        "\n",
        "# Get class names as a list\n",
        "class_names_found = sorted([entry.name for entry in list(os.scandir(target_directory)) if entry.is_dir()])\n",
        "class_names_found"
      ],
      "metadata": {
        "id": "BxAC4lGUoF3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
        "  \"\"\"\n",
        "  Finds the class folder names in a target directory.\n",
        "\n",
        "  Assumes target directory is in standard image classification.\n",
        "  \"\"\"\n",
        "  # Get the class names by scanning the target directory\n",
        "  classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
        "\n",
        "  # Raise an error if class names not found\n",
        "  if not classes:\n",
        "    raise FileNotFoundError(f\"Couldn't find any classes in {directory}.\")\n",
        "\n",
        "  # Create a dictionary of index labels\n",
        "  class_to_idx = {class_name: i for i, class_name in enumerate(classes)}\n",
        "  return classes, class_to_idx"
      ],
      "metadata": {
        "id": "DAqfnB0ZojpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_classes(target_directory)"
      ],
      "metadata": {
        "id": "heTiFTAZppQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a custom `DataSet` to replicate `ImageFolder`\n",
        "To create our own custom DataSet:\n",
        "1. Subclass `torch.utils.data.Dataset`\n",
        "2. Init our subclass with a target directory as well sa transform if we'd like to transform our data\n",
        "3. Create several attributes:\n",
        "  * paths - paths of our images\n",
        "  * transform - the transform we'd like to use\n",
        "  * classes - a list of the target classes\n",
        "  * class_to_id - a dict of the target classes mapped to integer labels\n",
        "4. Create a function to `load_images()`, this function will open an image\n",
        "5. Overwrite the `__len__()` method to return length of our dataset\n",
        "6. Overwrite the `__getitem__()` method to return a sample when passed an index"
      ],
      "metadata": {
        "id": "byXal0_8pvwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a custom dataset class\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# 1. Subclass torch.utils.data.Dataset\n",
        "class ImageFolderCustom(Dataset):\n",
        "  # 2. Initialize our custom dataset\n",
        "  def __init__(self,\n",
        "               target_dir: str,\n",
        "               transform: None):\n",
        "\n",
        "    # 3. Create class attributes\n",
        "    # Get all image paths\n",
        "    self.paths = list(pathlib.Path(target_dir).glob(\"*/*.jpg\"))\n",
        "\n",
        "    # Setup transfrom\n",
        "    self.transform = transform\n",
        "\n",
        "    # Setup class names and class to index mapping\n",
        "    self.classes, self.class_to_idx = find_classes(target_dir)\n",
        "\n",
        "  # 4. Create a function to load images\n",
        "  def load_image(self, index: int) -> Image.Image:\n",
        "    \"Opens an image via a path and returns it.\"\n",
        "    image_path = self.paths[index]\n",
        "    return Image.open(image_path)\n",
        "\n",
        "  # 5. Overwrite __len__()\n",
        "  def __len__(self) -> int:\n",
        "    \"Returns the total number of samples\"\n",
        "    return len(self.paths)\n",
        "\n",
        "  # 6. Overwrite __getitem__()\n",
        "  def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
        "    \"Returns one sample of data, data and label(X, y)\"\n",
        "    img = self.load_image(index)\n",
        "    class_name = self.paths[index].parent.name # expects path in format: data_folder/class_name/image.jpg\n",
        "    class_idx = self.class_to_idx[class_name]\n",
        "\n",
        "    # Transform if necessary\n",
        "    if self.transform:\n",
        "      return self.transform(img), class_idx\n",
        "    else:\n",
        "      return img, class_idx # return unstransformed image and label"
      ],
      "metadata": {
        "id": "bj0dHgEgrARq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a transform\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "  transforms.Resize(size=(64, 64)),\n",
        "  transforms.RandomHorizontalFlip(p=0.5),\n",
        "  transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "  transforms.Resize(size=(64, 64)),\n",
        "  transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "tteZxz5_s96y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out ImageFolderCustom\n",
        "train_data_custom = ImageFolderCustom(target_dir=train_dir, transform=train_transforms)\n",
        "test_data_custom = ImageFolderCustom(target_dir=test_dir, transform=test_transforms)"
      ],
      "metadata": {
        "id": "RoLz547rtoJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom, test_data_custom"
      ],
      "metadata": {
        "id": "irSBiQmCtyOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom.classes"
      ],
      "metadata": {
        "id": "m9BIHIWet0u_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom.class_to_idx"
      ],
      "metadata": {
        "id": "kmlKYKTyuCp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for equality between original ImageFolder Dataset and ImageFolderCustomDataset\n",
        "print(train_data_custom.classes == train_data.classes)\n",
        "print(test_data_custom.classes == test_data.classes)"
      ],
      "metadata": {
        "id": "6dgRDuZ-uKa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a function to display random images\n",
        "1. Take in a `Dataset` and a number of other parameters such as class names and how many images to visualize.\n",
        "2. To prevent the display getting out of hand, let's cap the number of images to see at 10.\n",
        "3. Set the ranodm seed for reproducibility.\n",
        "4. Get a list of random sample indexes from the target dataset.\n",
        "5. Setup a matplotlib plot.\n",
        "6. Loop through the random sample images and plot them with matplotlib.\n",
        "7. Make sure the dimensions of our images line up the matplotlib (height, width, color channels)"
      ],
      "metadata": {
        "id": "wZTDhPupuYyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create a function to take in a dataset\n",
        "def display_random_images(dataset: torch.utils.data.Dataset,\n",
        "                          classes: List[str] = None,\n",
        "                          n: int = 10,\n",
        "                          display_shape: bool = True,\n",
        "                          seed: int = None):\n",
        "\n",
        "  # 2. Adjust display if n is too high\n",
        "  if n > 10:\n",
        "    n = 10\n",
        "    display_shape = False\n",
        "    print(f\"For display purposes, n shouldn't be larger than 10, setting to 10.\")\n",
        "\n",
        "  # 3. Set the random seed\n",
        "  if seed:\n",
        "    random.seed(seed)\n",
        "\n",
        "  # 4. Get random sample indexes\n",
        "  random_samples_idx = random.sample(range(len(dataset)), k = n)\n",
        "\n",
        "  # 5. Setup plot\n",
        "  plt.figure(figsize=(16, 8))\n",
        "\n",
        "  # 6. Loop through random indexes and plot them with matplotlib\n",
        "  for i, targ_sample in enumerate(random_samples_idx):\n",
        "    targ_image, targ_label = dataset[targ_sample][0], dataset[targ_sample][1]\n",
        "\n",
        "    # 7. Adjust tensor dimensions for plotting\n",
        "    targ_image_adjust = targ_image.permute(1, 2, 0)\n",
        "\n",
        "    # Plot adjusted samples\n",
        "    plt.subplot(1, n, i + 1)\n",
        "    plt.imshow(targ_image_adjust)\n",
        "    plt.axis(False)\n",
        "    if classes:\n",
        "      title = f\"class: {classes[targ_label]}\"\n",
        "      if display_shape:\n",
        "        title = title + f\"\\nshape: {targ_image_adjust.shape}\"\n",
        "    plt.title(title)"
      ],
      "metadata": {
        "id": "hzM5N-vwuva5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display random images from the ImageFolder created Dataset\n",
        "display_random_images(train_data, classes=class_names, n=5, seed=None)"
      ],
      "metadata": {
        "id": "X0hJ60AtwMxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display random images from the ImageFolderCustom Dataset\n",
        "display_random_images(train_data_custom, classes=class_names, n=20, seed=42)"
      ],
      "metadata": {
        "id": "NLiiIougxCwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Turn custom loaded images into DataLoader"
      ],
      "metadata": {
        "id": "WvrwBIHBxUpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_dataloader_custom = DataLoader(dataset=train_data_custom,\n",
        "                                     batch_size=BATCH_SIZE,\n",
        "                                     shuffle=True,\n",
        "                                     num_workers=0)\n",
        "\n",
        "test_dataloader_custom = DataLoader(dataset=test_data_custom,\n",
        "                                    batch_size=BATCH_SIZE,\n",
        "                                    shuffle=False,\n",
        "                                    num_workers=0)\n",
        "\n",
        "train_dataloader_custom, test_dataloader_custom"
      ],
      "metadata": {
        "id": "0cRRnZQvxg5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get image and label from custom dataloader\n",
        "img_custom, label_custom = next(iter(train_dataloader_custom))\n",
        "img_custom.shape, label_custom.shape"
      ],
      "metadata": {
        "id": "o6ZjKUavxxB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Other forms of transforms (data augmentation)\n",
        "\n",
        "Data augmentation is the process of artificially adding diversity to your training data.\n",
        "\n",
        "In the case of image data, this may mean applying various image transformation to your image data.\n",
        "\n",
        "Let's take a look at one particular type of data augmentation used to train PyTorch vision models to state of the art levels."
      ],
      "metadata": {
        "id": "wGS71dGwx7bS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "WeUi-qEby0bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all image paths\n",
        "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
        "image_path_list[:10]"
      ],
      "metadata": {
        "id": "fKkX4SQMzacb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot random transformed images\n",
        "plot_transformed_images(image_path_list, train_transform, n=3, seed=None)"
      ],
      "metadata": {
        "id": "yNrRU72Vzic6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Model 0: TinyVGG without data augmentation"
      ],
      "metadata": {
        "id": "7ODQ0-12z1eb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating transforms and loading data for Model 0"
      ],
      "metadata": {
        "id": "FLkv0vgF0Ju0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create simple transform\n",
        "simple_transform = transforms.Compose([\n",
        "  transforms.Resize(size=(64, 64)),\n",
        "  transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "Cw7Pwtlp0Q2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load and transform data\n",
        "from torchvision import datasets\n",
        "\n",
        "train_data_simple = datasets.ImageFolder(root=train_dir, transform=simple_transform)\n",
        "test_data_simple = datasets.ImageFolder(root=test_dir, transform=simple_transform)\n",
        "\n",
        "# 2. Turn the datasets into DataLoaders\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setup batch size and number of works\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "# Create DataLoader's\n",
        "train_dataloader_simple = DataLoader(dataset=train_data_simple,\n",
        "                                     batch_size=BATCH_SIZE,\n",
        "                                     shuffle=True,\n",
        "                                     num_workers=NUM_WORKERS)\n",
        "\n",
        "test_dataloader_simple = DataLoader(dataset=test_data_simple,\n",
        "                                    batch_size=BATCH_SIZE,\n",
        "                                    shuffle=False,\n",
        "                                    num_workers=NUM_WORKERS)\n",
        "\n",
        "train_dataloader_simple, test_dataloader_simple"
      ],
      "metadata": {
        "id": "bIJPYH250aaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Create TinyVGG model class\n",
        "class TinyVGG(nn.Module):\n",
        "  \"\"\"Creates the TinyVGG architecture\"\"\"\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels = input_shape,\n",
        "                out_channels = hidden_units,\n",
        "                kernel_size = 3,\n",
        "                stride = 1,\n",
        "                padding = 0),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(in_channels = hidden_units,\n",
        "               out_channels = hidden_units,\n",
        "               kernel_size = 3,\n",
        "               stride = 1,\n",
        "               padding = 0),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    )\n",
        "\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels = hidden_units,\n",
        "                out_channels = hidden_units,\n",
        "                kernel_size = 3,\n",
        "                stride = 1,\n",
        "                padding = 0),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(in_channels = hidden_units,\n",
        "               out_channels = hidden_units,\n",
        "               kernel_size = 3,\n",
        "               stride = 1,\n",
        "               padding = 0),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(in_features=hidden_units*13*13, out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block_1(x)\n",
        "    #print(x.shape)\n",
        "    x = self.conv_block_2(x)\n",
        "    #print(x.shape)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "    #return self.classifier(self.conv_block_2(self.conv_block_1(x))) # benefits from operator fusion"
      ],
      "metadata": {
        "id": "g_bShr2x0ygE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_0 = TinyVGG(input_shape=3, hidden_units=10, output_shape=len(class_names)).to(device)\n",
        "model_0"
      ],
      "metadata": {
        "id": "U6fboYZ60zl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try a forward pass on a single image (to test the model)"
      ],
      "metadata": {
        "id": "jyBcREQV2Q3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a single image batch\n",
        "image_batch, label_batch = next(iter(train_dataloader_simple))\n",
        "image_single, label_single = image_batch[0].unsqueeze(dim=0), label_batch[0] # We have shape mismatch due to flattening. So, we have to unsqueeze.\n",
        "image_single.shape, label_single.shape"
      ],
      "metadata": {
        "id": "o-STRvdz2m2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0(image_batch.to(device))"
      ],
      "metadata": {
        "id": "IJOZHW7p27yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use `torchinfo` to get an idea of the shapes going through our model"
      ],
      "metadata": {
        "id": "nIR0ZKMW3AAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install torchinfo, import if its available\n",
        "try:\n",
        "  import torchinfo\n",
        "except:\n",
        "  !pip install torchinfo\n",
        "  import torchinfo\n",
        "\n",
        "from torchinfo import summary\n",
        "summary(model_0, input_size=(1, 3, 64, 64))"
      ],
      "metadata": {
        "id": "C-tSm_fq4B3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create train and test loop\n",
        "* `train_step()` - takes in a model and dataloader and trains the model on the dataloader\n",
        "* `test_step()` - takes in a model and dataloader and evaluates the model on the dataloader"
      ],
      "metadata": {
        "id": "Sgk7KVRT4Koj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train_step()\n",
        "def train_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              optimizer: torch.optim.Optimizer,\n",
        "              device: torch.device):\n",
        "\n",
        "  # Put the model in train mode\n",
        "  model.train()\n",
        "\n",
        "  # Train loss and accuracy\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  # Loop through dataloader data batches\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    # Send data to target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # Forward Pass\n",
        "    y_pred = model(X) # Ouputs logits\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    # Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    # Calculate accuracy metric\n",
        "    y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "    train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "  # Adjust metrics to get average loss and accuracy per batch\n",
        "  train_loss = train_loss / len(dataloader)\n",
        "  train_acc = train_acc / len(dataloader)\n",
        "  return train_loss, train_acc"
      ],
      "metadata": {
        "id": "Rh9IZ-s6XwFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a test step\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device):\n",
        "\n",
        "  # Put model in eval mode\n",
        "  model.eval()\n",
        "\n",
        "  # Setup test loss and test accuracy values\n",
        "  test_loss, test_acc = 0, 0\n",
        "\n",
        "  # Turn on inference context manager\n",
        "  with torch.inference_mode():\n",
        "\n",
        "    # Loop through DataLoader batches\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "      # Send data to target device\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      # Forward Pass\n",
        "      test_pred_logits = model(X)\n",
        "\n",
        "      # Calculate loss\n",
        "      loss = loss_fn(test_pred_logits, y)\n",
        "      test_loss += loss.item()\n",
        "\n",
        "      # Calculate accuracy\n",
        "      test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "      test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "  # Adjust metrics to get average loss and accuracy per batch\n",
        "  test_loss = test_loss / len(dataloader)\n",
        "  test_acc = test_acc / len(dataloader)\n",
        "  return test_loss, test_acc"
      ],
      "metadata": {
        "id": "wjZWywdjYxPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a `train()` function to combine and `train_step()` and `test_step()`"
      ],
      "metadata": {
        "id": "wY3Nj24hZU8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Create a train function that takes in various model parameters, optimizer, dataloader, loss function, etc.\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
        "          epochs: int = 5,\n",
        "          device = device):\n",
        "\n",
        "  # Create empty results dictionary\n",
        "  results = {\"train_loss\": [],\n",
        "            \"train_acc\": [],\n",
        "            \"test_loss\": [],\n",
        "            \"test_acc\": []}\n",
        "\n",
        "  # Loop through training and testing steps for a number of epochs\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_acc = train_step(model=model,\n",
        "                                       dataloader=train_dataloader,\n",
        "                                       loss_fn=loss_fn,\n",
        "                                       optimizer=optimizer,\n",
        "                                       device=device)\n",
        "\n",
        "    test_loss, test_acc = test_step(model=model,\n",
        "                                    dataloader=test_dataloader,\n",
        "                                    loss_fn=loss_fn,\n",
        "                                    device=device)\n",
        "\n",
        "    # Print out what's happening\n",
        "    print(\n",
        "        f\"Epoch: {epoch} | train_loss: {train_loss:4f} | train_acc: {train_acc:4f} | test_loss: {test_loss:4f} | test_acc: {test_acc:4f}\"\n",
        "    )\n",
        "\n",
        "    # Update results dictionary\n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"train_acc\"].append(train_acc)\n",
        "    results[\"test_loss\"].append(test_loss)\n",
        "    results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "  # Return the filled results at the end of the epochs\n",
        "  return results\n"
      ],
      "metadata": {
        "id": "qVCUTtnjZeoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and evaluate model 0"
      ],
      "metadata": {
        "id": "970RY6EGa9AU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Set the number of epochs\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# Recreate an instance of TinyVGG\n",
        "model_0 = TinyVGG(input_shape=3, hidden_units=10, output_shape=len(train_data.classes)).to(device)\n",
        "\n",
        "# Create the loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)\n",
        "\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# Train model 0\n",
        "model_0_results = train(model=model_0,\n",
        "                        train_dataloader=train_dataloader_simple,\n",
        "                        test_dataloader=test_dataloader_simple,\n",
        "                        optimizer=optimizer,\n",
        "                        loss_fn=loss_fn,\n",
        "                        epochs=NUM_EPOCHS,\n",
        "                        device=device)\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
      ],
      "metadata": {
        "id": "Jt3utTTQbIxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_results"
      ],
      "metadata": {
        "id": "UfDPAlfBbvFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot the loss curves of Model 0\n",
        "A loss curve is a way to track your model's progress over time."
      ],
      "metadata": {
        "id": "E8iLg59Bb7cQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the model 0 results keys\n",
        "model_0_results.keys()"
      ],
      "metadata": {
        "id": "F9cMQcvscES8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_curves(results: Dict[str, List[float]]):\n",
        "  \"\"\"Plots training curves of a results dictionary.\"\"\"\n",
        "\n",
        "  # Get the loss values of the results dictionary (training and test)\n",
        "  loss = results[\"train_loss\"]\n",
        "  test_loss = results[\"test_loss\"]\n",
        "\n",
        "  # Get the accuracy values of the results dictionary (training and test)\n",
        "  accuracy = results[\"train_acc\"]\n",
        "  test_accuracy = results[\"test_acc\"]\n",
        "\n",
        "  # Figure out how many epochs there were\n",
        "  epochs = range(len(results[\"train_loss\"]))\n",
        "\n",
        "  # Setup a plot\n",
        "  plt.figure(figsize=(15, 7))\n",
        "\n",
        "  # Plot the loss\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(epochs, loss, label=\"train_loss\")\n",
        "  plt.plot(epochs, test_loss, label=\"test_loss\")\n",
        "  plt.title(\"Loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot the accuracy\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(epochs, accuracy, label=\"train_accuracy\")\n",
        "  plt.plot(epochs, test_accuracy, label=\"test_accuracy\")\n",
        "  plt.title(\"Accuracy\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "DTFQKh4hcU4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(model_0_results) # This could be underfitting or overfitting"
      ],
      "metadata": {
        "id": "K-kjr-vZc1iQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. TinyVGG with Data Augmentation"
      ],
      "metadata": {
        "id": "WNnaM15Xc2fp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create, transform with data augmentation"
      ],
      "metadata": {
        "id": "TmIt86MudmRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training transform with TrivialAugment\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transform_trivial = transforms.Compose([\n",
        "  transforms.Resize(size=(64, 64)),\n",
        "  transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "  transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_transform_simple = transforms.Compose([\n",
        "  transforms.Resize(size=(64, 64)),\n",
        "  transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "7C9BjfmxdvWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create train and test Dataset and DataLoader with data augmentation"
      ],
      "metadata": {
        "id": "iipTu92Bd-Bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn image folders into Datasets\n",
        "from torchvision import datasets\n",
        "train_data_augmented = datasets.ImageFolder(root=train_dir, transform=train_transform_trivial)\n",
        "train_data_simple = datasets.ImageFolder(root=train_dir, transform=test_transform_simple)"
      ],
      "metadata": {
        "id": "MjFDazqFeC2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn datasets into DataLoaders\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setup batch size and number of works\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_dataloader_augmented = DataLoader(dataset=train_data_augmented,\n",
        "                                         batch_size=BATCH_SIZE,\n",
        "                                         shuffle=True,\n",
        "                                         num_workers=NUM_WORKERS)\n",
        "\n",
        "test_dataloader_simple = DataLoader(dataset=train_data_simple,\n",
        "                                    batch_size=BATCH_SIZE,\n",
        "                                    shuffle=False,\n",
        "                                    num_workers=NUM_WORKERS)"
      ],
      "metadata": {
        "id": "pBgo557FeSzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct and train model 1\n",
        "\n",
        "Only thing we've changed is augment the data"
      ],
      "metadata": {
        "id": "12WqAi1Nencf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model_1 and send it to the target device\n",
        "torch.manual_seed(42)\n",
        "model_1 = TinyVGG(input_shape=3, hidden_units=10, output_shape=len(train_data_augmented.classes)).to(device)\n",
        "model_1"
      ],
      "metadata": {
        "id": "OcnC8z60exgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Set the number of epochs\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# Setup loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Setup optimizer\n",
        "optimizer = torch.optim.Adam(params=model_1.parameters(), lr=0.001)\n",
        "\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# Train model_1\n",
        "model_1_results = train(model=model_1,\n",
        "                        train_dataloader=train_dataloader_augmented,\n",
        "                        test_dataloader=test_dataloader_simple,\n",
        "                        optimizer=optimizer,\n",
        "                        loss_fn=loss_fn,\n",
        "                        epochs=NUM_EPOCHS,\n",
        "                        device=device)\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"Total training time for model_1: {end_time-start_time:.3f} seconds\")"
      ],
      "metadata": {
        "id": "Okt9pJppe_9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results"
      ],
      "metadata": {
        "id": "G9EZnT70fcLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Plot the loss curves of model 1\n",
        "plot_loss_curves(model_1_results)"
      ],
      "metadata": {
        "id": "ne3bjb6RfkdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Compare model results\n",
        "Ways to compare:\n",
        "1. Hard coding (what we're doing)\n",
        "2. PyTorch + TensorBoard\n",
        "3. Weights and Biases\n",
        "4. MLFlow"
      ],
      "metadata": {
        "id": "ATLgXfFdftEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "model_0_df = pd.DataFrame(model_0_results)\n",
        "model_1_df = pd.DataFrame(model_1_results)\n",
        "model_0_df"
      ],
      "metadata": {
        "id": "iSBZL7ruf09P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup a plot\n",
        "plt.figure(figsize = (15, 10))\n",
        "\n",
        "# Get number of epochs\n",
        "epochs = range(len(model_0_df))\n",
        "\n",
        "# Plot train loss\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs, model_0_df[\"train_loss\"], label=\"model_0_train_loss\")\n",
        "plt.plot(epochs, model_1_df[\"train_loss\"], label=\"model_1_train_loss\")\n",
        "plt.title(\"Train Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot test loss\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs, model_0_df[\"test_loss\"], label=\"model_0_test_loss\")\n",
        "plt.plot(epochs, model_1_df[\"test_loss\"], label=\"model_1_test_loss\")\n",
        "plt.title(\"Test Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot train accuracy\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(epochs, model_0_df[\"train_acc\"], label=\"model_0_train_acc\")\n",
        "plt.plot(epochs, model_1_df[\"train_acc\"], label=\"model_1_train_acc\")\n",
        "plt.title(\"Train Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot test accuracy\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(epochs, model_0_df[\"test_acc\"], label=\"model_0_test_acc\")\n",
        "plt.plot(epochs, model_1_df[\"test_acc\"], label=\"model_1_test_acc\")\n",
        "plt.title(\"Test Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "9d62SJ2qgHwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Making a prediction on a custom image"
      ],
      "metadata": {
        "id": "41vhkeR2ghyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download custom image\n",
        "import requests\n",
        "\n",
        "# Setup custom image path\n",
        "custom_image_path = data_path / \"04-pizza-dad.jpeg\"\n",
        "\n",
        "# Download the image if it doesn't already exist\n",
        "if not custom_image_path.is_file():\n",
        "    with open(custom_image_path, \"wb\") as f:\n",
        "        # When downloading from GitHub, need to use the \"raw\" file link\n",
        "        request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pizza-dad.jpeg\")\n",
        "        print(f\"Downloading {custom_image_path}...\")\n",
        "        f.write(request.content)\n",
        "else:\n",
        "    print(f\"{custom_image_path} already exists, skipping download.\")"
      ],
      "metadata": {
        "id": "wm-bbmYxg76Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading in a custom image with PyTorch\n",
        "We have to make sure our custom image is in the same format as the data our model was trained on. It has to have the right datatype, shape, and device."
      ],
      "metadata": {
        "id": "eFuZsSuNiIVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "\n",
        "# Read in custom image\n",
        "custom_image_uint8 = torchvision.io.read_image(str(custom_image_path))\n",
        "\n",
        "# Print out image data\n",
        "print(f\"Custom image tensor:\\n{custom_image_uint8}\\n\")\n",
        "print(f\"Custom image shape: {custom_image_uint8.shape}\\n\")\n",
        "print(f\"Custom image dtype: {custom_image_uint8.dtype}\")"
      ],
      "metadata": {
        "id": "R_-GTu_9iUJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(custom_image_uint8.permute(1, 2, 0))"
      ],
      "metadata": {
        "id": "nRNdZtasikjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making a prediction on a custom image with a PyTorch model"
      ],
      "metadata": {
        "id": "7Y4HkUoxjoLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the custom image and convert to torch.float32\n",
        "custom_image = torchvision.io.read_image(str(custom_image_path)).type(torch.float32) / 255. # to make the values be between 0 and 1\n",
        "custom_image"
      ],
      "metadata": {
        "id": "Fye8aWcNkDpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(custom_image.permute(1, 2, 0))"
      ],
      "metadata": {
        "id": "CyswOhK2kgKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create transform pipeline to resize image\n",
        "from torchvision import transforms\n",
        "custom_image_transform = transforms.Compose([\n",
        "  transforms.Resize(size=(64, 64)),\n",
        "])\n",
        "\n",
        "# Transform target image\n",
        "custom_image_transformed = custom_image_transform(custom_image)\n",
        "\n",
        "# Print out the shapes\n",
        "print(f\"Original shape: {custom_image.shape}\")\n",
        "print(f\"Transformed shape: {custom_image_transformed.shape}\")"
      ],
      "metadata": {
        "id": "uYXuCmP-krWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.eval()\n",
        "with torch.inference_mode():\n",
        "    # Add an extra dimension to image\n",
        "    custom_image_transformed_with_batch_size = custom_image_transformed.unsqueeze(dim=0)\n",
        "\n",
        "    # Print out different shapes\n",
        "    print(f\"Custom image transformed shape: {custom_image_transformed.shape}\")\n",
        "    print(f\"Unsqueezed custom image shape: {custom_image_transformed_with_batch_size.shape}\")\n",
        "\n",
        "    # Make a prediction on image with an extra dimension\n",
        "    custom_image_pred = model_1(custom_image_transformed.unsqueeze(dim=0).to(device))"
      ],
      "metadata": {
        "id": "5Sts0R30jwF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make prediction on a custom image, we had to:\n",
        "1. Load the image and turn it into a tensor.\n",
        "2. Make sure the image was the same datatype as the model\n",
        "3. Make sure the image was the same shape as the data the model was trained on\n",
        "4. Make sure the image was on the same device as our model"
      ],
      "metadata": {
        "id": "lc4SkThdkqeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert logits -> prediction probabilities\n",
        "custom_image_pred_probs = torch.softmax(custom_image_pred, dim=1)\n",
        "custom_image_pred_probs"
      ],
      "metadata": {
        "id": "RFt0WF5GlpZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conver prediction probabilities -> prediction labels\n",
        "custom_image_pred_label = torch.argmax(custom_image_pred_probs, dim=1)\n",
        "custom_image_pred_label"
      ],
      "metadata": {
        "id": "y1qDqflzl36K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names[custom_image_pred_label]"
      ],
      "metadata": {
        "id": "-JXdinJMl-ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting custom image prediction together: building a function\n",
        "Ideal outcome is a function where we pass an image path to and have our model predict on that image + prediction"
      ],
      "metadata": {
        "id": "gXPGygvTmDIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_and_plot_image(model: torch.nn.Module,\n",
        "                        image_path: str,\n",
        "                        class_names: List[str] = None,\n",
        "                        transform=None,\n",
        "                        device: torch.device = device):\n",
        "    \"\"\"Makes a prediction on a target image and plots the image with its prediction.\"\"\"\n",
        "\n",
        "    # 1. Load in image and convert the tensor values to float32\n",
        "    target_image = torchvision.io.read_image(str(image_path)).type(torch.float32)\n",
        "\n",
        "    # 2. Divide the image pixel values by 255 to get them between [0, 1]\n",
        "    target_image = target_image / 255.\n",
        "\n",
        "    # 3. Transform if necessary\n",
        "    if transform:\n",
        "        target_image = transform(target_image)\n",
        "\n",
        "    # 4. Make sure the model is on the target device\n",
        "    model.to(device)\n",
        "\n",
        "    # 5. Turn on model evaluation mode and inference mode\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        # Add an extra dimension to the image\n",
        "        target_image = target_image.unsqueeze(dim=0)\n",
        "\n",
        "        # Make a prediction on image with an extra dimension and send it to the target device\n",
        "        target_image_pred = model(target_image.to(device))\n",
        "\n",
        "    # 6. Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification)\n",
        "    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n",
        "\n",
        "    # 7. Convert prediction probabilities -> prediction labels\n",
        "    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n",
        "\n",
        "    # 8. Plot the image alongside the prediction and prediction probability\n",
        "    plt.imshow(target_image.squeeze().permute(1, 2, 0)) # make sure it's the right size for matplotlib\n",
        "    if class_names:\n",
        "        title = f\"Pred: {class_names[target_image_pred_label.cpu()]} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
        "    else:\n",
        "        title = f\"Pred: {target_image_pred_label} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
        "    plt.title(title)\n",
        "    plt.axis(False);"
      ],
      "metadata": {
        "id": "tneP2YKJmR6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pred on our custom image\n",
        "pred_and_plot_image(model=model_1,\n",
        "                    image_path=custom_image_path,\n",
        "                    class_names=class_names,\n",
        "                    transform=custom_image_transform,\n",
        "                    device=device)\n",
        "\n",
        "# Our model seems to be guessing.\n",
        "# This won't be the case with other images though.\n",
        "# The picture of the man reduces the probability."
      ],
      "metadata": {
        "id": "-raG_Fxune56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nra3SeWvn1fF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}